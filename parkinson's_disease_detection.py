# -*- coding: utf-8 -*-
"""Parkinson's Disease Detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1brlqfqVA2fJdOS5PYl4gWm1Yd_JNdYmw

Importing the Dependencies
"""

from google.colab import drive
drive.mount('/content/drive')

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn import svm
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt
import seaborn as sns
sns.set_style('darkgrid')

"""Data Collection & Analysis"""

# loading the data from csv file to a Pandas DataFrame
parkinsons_data = pd.read_csv('/content/parkinsons.csv')

# printing the first 5 rows of the dataframe
parkinsons_data.head()

# number of rows and columns in the dataframe
parkinsons_data.shape

# getting more information about the dataset
parkinsons_data.info()

parkinsons_data.dtypes

# checking for missing values in each column
parkinsons_data.isnull().sum()

# getting some statistical measures about the data
parkinsons_data.describe()

# distribution of target Variable
parkinsons_data['status'].value_counts()

"""1  --> Parkinson's Positive

0 --> Healthy

Data Pre-Processing

Separating the features & Target
"""

parkinsons_data.columns
features_data = parkinsons_data[[ 'MDVP:Fo(Hz)', 'MDVP:Fhi(Hz)', 'MDVP:Flo(Hz)', 'MDVP:Jitter(%)',
       'MDVP:Jitter(Abs)', 'MDVP:RAP', 'MDVP:PPQ', 'Jitter:DDP',
       'MDVP:Shimmer', 'MDVP:Shimmer(dB)', 'Shimmer:APQ3', 'Shimmer:APQ5',
       'MDVP:APQ', 'Shimmer:DDA', 'NHR', 'HNR', 'RPDE', 'DFA',
       'spread1', 'spread2', 'D2', 'PPE']]

X=np.asarray(features_data)

X=np.asarray(features_data)
Y = parkinsons_data['status']

print(X)

print(Y)

"""Splitting the data to training data & Test data"""

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)

print(X.shape, X_train.shape, X_test.shape)

model = svm.SVC(kernel='linear')

model.fit(X_train, Y_train)

"""Data Standardization"""

scaler = StandardScaler()

scaler.fit(X_train)

X_train = scaler.transform(X_train)

X_test = scaler.transform(X_test)

print(X_train)

"""Model Training

Support Vector Machine Model
"""

model = svm.SVC(kernel='linear')

# training the SVM model with training data
model.fit(X_train, Y_train)

model_p = svm.SVC(kernel='rbf')

model_p.fit(X_train, Y_train)
print(model_p.kernel)

"""Model Evaluation

Accuracy Score
"""

# accuracy score on training data
X_train_prediction = model.predict(X_train)
training_data_accuracy = accuracy_score(Y_train, X_train_prediction)

print('Accuracy score of training data : ', training_data_accuracy)

# accuracy score on training data
X_test_prediction = model.predict(X_test)
test_data_accuracy = accuracy_score(Y_test, X_test_prediction)

print('Accuracy score of test data : ', test_data_accuracy)

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

"""Evaluation metrics for linear Model"""

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report

# Assuming you have already trained your SVM model and obtained predictions for both training and test sets

# Predictions on training data
X_train_prediction = model.predict(X_train)

# Predictions on test data
X_test_prediction = model.predict(X_test)

# Compute accuracy scores
training_data_accuracy = accuracy_score(Y_train, X_train_prediction)
test_data_accuracy = accuracy_score(Y_test, X_test_prediction)

print('Accuracy score of training data:', training_data_accuracy)
print('Accuracy score of test data:', test_data_accuracy)

# Compute precision, recall, and F1-score for training and test data
precision_train = precision_score(Y_train, X_train_prediction)
recall_train = recall_score(Y_train, X_train_prediction)
f1_train = f1_score(Y_train, X_train_prediction)

precision_test = precision_score(Y_test, X_test_prediction)
recall_test = recall_score(Y_test, X_test_prediction)
f1_test = f1_score(Y_test, X_test_prediction)

print('Precision, Recall, and F1-score for training data:')
print('Precision:', precision_train)
print('Recall:', recall_train)
print('F1-score:', f1_train)

print('Precision, Recall, and F1-score for test data:')
print('Precision:', precision_test)
print('Recall:', recall_test)
print('F1-score:', f1_test)

# Print classification report for training and test data
print('Classification Report for Training Data:')
print(classification_report(Y_train, X_train_prediction))

print('Classification Report for Test Data:')
print(classification_report(Y_test, X_test_prediction))

"""Building a Predictive System"""

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report

# Predictions on training data for linear kernel model
X_train_prediction_linear = model.predict(X_train)

# Predictions on test data for linear kernel model
X_test_prediction_linear = model.predict(X_test)

# Predictions on training data for RBF kernel model
X_train_prediction_rbf = model_p.predict(X_train)

# Predictions on test data for RBF kernel model
X_test_prediction_rbf = model_p.predict(X_test)

# Compute accuracy scores for both models
accuracy_train_linear = accuracy_score(Y_train, X_train_prediction_linear)
accuracy_test_linear = accuracy_score(Y_test, X_test_prediction_linear)

accuracy_train_rbf = accuracy_score(Y_train, X_train_prediction_rbf)
accuracy_test_rbf = accuracy_score(Y_test, X_test_prediction_rbf)

print('Accuracy score for linear kernel model on training data:', accuracy_train_linear)
print('Accuracy score for linear kernel model on test data:', accuracy_test_linear)

print('Accuracy score for RBF kernel model on training data:', accuracy_train_rbf)
print('Accuracy score for RBF kernel model on test data:', accuracy_test_rbf)

# Compute precision, recall, and F1-score for both models
precision_train_linear = precision_score(Y_train, X_train_prediction_linear)
recall_train_linear = recall_score(Y_train, X_train_prediction_linear)
f1_train_linear = f1_score(Y_train, X_train_prediction_linear)

precision_test_linear = precision_score(Y_test, X_test_prediction_linear)
recall_test_linear = recall_score(Y_test, X_test_prediction_linear)
f1_test_linear = f1_score(Y_test, X_test_prediction_linear)

precision_train_rbf = precision_score(Y_train, X_train_prediction_rbf)
recall_train_rbf = recall_score(Y_train, X_train_prediction_rbf)
f1_train_rbf = f1_score(Y_train, X_train_prediction_rbf)

precision_test_rbf = precision_score(Y_test, X_test_prediction_rbf)
recall_test_rbf = recall_score(Y_test, X_test_prediction_rbf)
f1_test_rbf = f1_score(Y_test, X_test_prediction_rbf)

print('\nPrecision, Recall, and F1-score for linear kernel model on training data:')
print('Precision:', precision_train_linear)
print('Recall:', recall_train_linear)
print('F1-score:', f1_train_linear)

print('Precision, Recall, and F1-score for linear kernel model on test data:')
print('Precision:', precision_test_linear)
print('Recall:', recall_test_linear)
print('F1-score:', f1_test_linear)

print('\nPrecision, Recall, and F1-score for RBF kernel model on training data:')
print('Precision:', precision_train_rbf)
print('Recall:', recall_train_rbf)
print('F1-score:', f1_train_rbf)

print('Precision, Recall, and F1-score for RBF kernel model on test data:')
print('Precision:', precision_test_rbf)
print('Recall:', recall_test_rbf)
print('F1-score:', f1_test_rbf)

# Print classification report for both models
print('\nClassification Report for linear kernel model on Training Data:')
print(classification_report(Y_train, X_train_prediction_linear))

print('Classification Report for linear kernel model on Test Data:')
print(classification_report(Y_test, X_test_prediction_linear))

print('\nClassification Report for RBF kernel model on Training Data:')
print(classification_report(Y_train, X_train_prediction_rbf))

print('Classification Report for RBF kernel model on Test Data:')
print(classification_report(Y_test, X_test_prediction_rbf))

"""hyper tuning using grid"""

from sklearn.model_selection import GridSearchCV
from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report

# Assuming you have X_train, X_test, Y_train, Y_test and the predictions X_train_prediction_rbf, X_test_prediction_rbf

# Standardize features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Define SVM with RBF kernel
model_p = SVC(kernel='rbf')

# Define hyperparameters to tune
param_grid = {'C': [0.1, 1, 10, 100], 'gamma': [0.1, 0.01, 0.001, 0.0001]}

# Perform GridSearchCV
grid_search = GridSearchCV(model_p, param_grid, cv=5, scoring='accuracy')
grid_search.fit(X_train, Y_train)

# Best hyperparameters
best_params = grid_search.best_params_
print("Best Hyperparameters:", best_params)

# Best model
best_model = grid_search.best_estimator_

# Predictions on training and test data
Y_train_pred = best_model.predict(X_train)
Y_test_pred = best_model.predict(X_test)

# Compute evaluation metrics
accuracy_train = accuracy_score(Y_train, Y_train_pred)
accuracy_test = accuracy_score(Y_test, Y_test_pred)

precision_train = precision_score(Y_train, Y_train_pred)
recall_train = recall_score(Y_train, Y_train_pred)
f1_train = f1_score(Y_train, Y_train_pred)

precision_test = precision_score(Y_test, Y_test_pred)
recall_test = recall_score(Y_test, Y_test_pred)
f1_test = f1_score(Y_test, Y_test_pred)

# Print evaluation metrics
print("Accuracy score for training data:", accuracy_train)
print("Accuracy score for test data:", accuracy_test)

print("\nPrecision, Recall, and F1-score for training data:")
print("Precision:", precision_train)
print("Recall:", recall_train)
print("F1-score:", f1_train)

print("\nPrecision, Recall, and F1-score for test data:")
print("Precision:", precision_test)
print("Recall:", recall_test)
print("F1-score:", f1_test)

# Print classification report
print("\nClassification Report for training data:")
print(classification_report(Y_train, Y_train_pred))

print("\nClassification Report for test data:")
print(classification_report(Y_test, Y_test_pred))

import numpy as np

# Input data
input_data = (197.07600,206.89600,192.05500,0.00289,0.00001,0.00166,0.00168,0.00498,0.01098,0.09700,0.00563,0.00680,0.00802,0.01689,0.00339,26.77500,0.422229,0.741367,-7.348300,0.177551,1.743867,0.085569)

# Changing input data to a numpy array and reshaping it
input_data_as_numpy_array = np.asarray(input_data)
input_data_reshaped = input_data_as_numpy_array.reshape(1, -1)

# Standardize the data
std_data = scaler.transform(input_data_reshaped)

# Predict using the best model obtained from GridSearchCV
prediction = best_model.predict(std_data)

# Print prediction
if prediction[0] == 0:
    print("The person does not have Parkinson's disease.")
else:
    print("The person has Parkinson's disease.")

from sklearn.linear_model import LogisticRegression

clf=LogisticRegression()
#TrainMode
clf.fit(X_train,Y_train)

pred_logistic_test=clf.predict(X_test)
pred_logistic_train=clf.predict(X_train)

from sklearn.metrics import accuracy_score
print("TrainingAccuracy:",accuracy_score(Y_train,pred_logistic_train))
print("TestAccuracy:",accuracy_score(Y_test,pred_logistic_test))

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report

# Assuming you have already obtained predictions for both training and test sets: pred_logistic_train, pred_logistic_test

# Compute accuracy scores
training_accuracy = accuracy_score(Y_train, pred_logistic_train)
test_accuracy = accuracy_score(Y_test, pred_logistic_test)

print("Training Accuracy:", training_accuracy)
print("Test Accuracy:", test_accuracy)

# Compute precision scores
training_precision = precision_score(Y_train, pred_logistic_train)
test_precision = precision_score(Y_test, pred_logistic_test)

print("Training Precision:", training_precision)
print("Test Precision:", test_precision)

# Compute recall scores
training_recall = recall_score(Y_train, pred_logistic_train)
test_recall = recall_score(Y_test, pred_logistic_test)

print("Training Recall:", training_recall)
print("Test Recall:", test_recall)

# Compute F1-scores
training_f1 = f1_score(Y_train, pred_logistic_train)
test_f1 = f1_score(Y_test, pred_logistic_test)

print("Training F1-score:", training_f1)
print("Test F1-score:", test_f1)

# Print classification report for training and test data
print("Classification Report for Training Data:")
print(classification_report(Y_train, pred_logistic_train))

print("Classification Report for Test Data:")
print(classification_report(Y_test, pred_logistic_test))

from sklearn.metrics import precision_score

# Compute precision for training set
precision_train = precision_score(Y_train, pred_logistic_train)

# Compute precision for test set
precision_test = precision_score(Y_test, pred_logistic_test)

print("Training Precision:", precision_train)
print("Test Precision:", precision_test)

from sklearn.metrics import  classification_report

# Classification report for training data
print("\nClassification Report for Training Data:")
print(classification_report(Y_train, pred_logistic_train))

print("\nClassification Report for Testing Data:")
print(classification_report(Y_test, pred_logistic_test))

